You are extending an EXISTING scaffold repo for a LOCAL coding agent (Cursor-style) that edits codebases via staged diffs and user approval.

CONTEXT (what already exists)
- There is a VM-friendly `bootstrap.py` that:
  - creates `venv/`, installs `requirements.txt`
  - installs RLM (best-effort)
  - detects/asks GPU VRAM and selects a GGUF quant hint
  - downloads GGUF models from HuggingFace
  - starts a FastAPI server (OpenAPI docs at /docs)
- There are existing modules: agent/, indexer/, patcher/, vcs/, server/, scripts/, configs/
- Git approval + ring buffer for last 3 restore commits exists (approval=commit, revert supported).
- Current /propose endpoint may be a placeholder. Your job is to implement the real agent loop.

GOALS
- User submits a request about a codebase. If scope is unclear, the agent asks clarifying questions.
- Agent reads repo, builds/maintains a hybrid code index (“RAG”):
  (1) structured symbol index (defs/refs/calls/imports)
  (2) exact retrieval via ripgrep
  (3) optional embeddings later (not required for MVP)
- Agent proposes edits as a PENDING PATCH in staging. Base code is not modified until approval.
- Must support “iterate on pending patch” when user requests changes without approving.
- UI must show git-style diffs (red deletions, green additions). For MVP, API returns unified diff + summary.
- Shell commands (tests/build/mkdir/etc.) MUST run ONLY after explicit user confirmation ("YES"). No silent execution.
- Each approval becomes a git commit. Keep a ring buffer of last 3 approved commits for revert; drop oldest on 4th.
- After approval, keep prompts short and avoid context bloat:
  - Use RLM harness so large context stays external (variables/DB), not in prompt.
  - Implement a “reset context” behavior after each approval: clear pending patch state and clear RLM variables except minimal metadata.

RLM REQUIREMENT (must implement)
- Integrate Recursive Language Models using:
  - preferred: https://github.com/alexzhang13/rlm
  - fallback: https://github.com/ysz/recursive-llm
- All LLM calls must go through an abstraction layer:
  - plain llama.cpp backend for GGUF inference (llama-cpp-python)
  - wrapped in rlm.completion/chat so large context is stored externally
- Provide an explicit endpoint or CLI command: /reset_context
  - clears pending patch
  - clears RLM variable store for the current repo/session
  - keeps only: repo_root, HEAD commit, model config, index version pointer

MODEL POLICY (VRAM-based)
- The system must ask/detect VRAM in bootstrap and pick model sizes/quantization accordingly.
- Provide a simple heuristic:
  - 0 GB (CPU-only): use smallest reasonable models + low context
  - <= 8 GB: prefer 7B models, Q4_K_M, context 4k-8k
  - 9–12 GB: 7B–14B where possible, Q5_K_M, context up to 8k
  - 13–24 GB: larger models/quant Q6_K and higher context
- Reasoner model: DeepSeek reasoning-style (7B default) OR equivalent.
- Coder model: Qwen2.5-Coder (7B default) OR larger if VRAM allows.
- VLM: Qwen-VL optional; disabled by default and only loaded if enabled.
- Keep configs in configs/config.yaml and update them via bootstrap.

LANGUAGE COVERAGE (initial MVP)
- Python, JavaScript/TypeScript, JSON/YAML, Markdown, HTML/CSS.
- Use Tree-sitter for parsing and symbol extraction.
- Use ripgrep for exact search.
- LSP integration can be added AFTER MVP.

DELIVERABLES
- Work inside the existing repo structure. Do NOT rewrite the scaffold; extend it cleanly.
- Keep the “upload → run bootstrap.py → server starts” flow working.
- Produce runnable code after each milestone.

REPO STRUCTURE (keep/extend)
- agent/      orchestrator + state machine + tool router + LLM abstraction
- indexer/    tree-sitter parsing, symbol DB, incremental updates, ripgrep retrieval
- patcher/    staging workspace, unified diff generation, apply/rebase
- vcs/        git integration, commit ring buffer, revert
- server/     FastAPI endpoints and request/response schemas
- rlm_wrap/   RLM wrappers + variable store + reset/clear functions
- scripts/    model download scripts (already present)
- configs/    config.yaml (already present)
- tests/      unit tests (add)

API CONTRACT (MVP endpoints; extend existing)
- POST /init { repo_root }:
  - ensures git repo, creates/loads index, prepares staging
  - returns restore points, index status, HEAD commit
- POST /query { user_text }:
  - runs reasoner: clarifies if needed OR returns a plan
  - if clarification needed: returns questions and state=NEEDS_INFO
- POST /propose { user_text }:
  - runs retrieve->plan->coder to produce a unified diff (pending patch)
  - stores pending patch server-side
  - returns: diff, summary, touched_files, risk_notes
- POST /revise_pending { user_text }:
  - modifies the pending diff minimally based on new request (no approval yet)
  - returns updated diff + summary
- POST /approve { message? }:
  - applies pending diff to base repo, commits, updates ring buffer
  - updates index incrementally (or full reindex for MVP)
  - clears pending patch and resets LLM context (RLM variable cleanup)
- POST /reject:
  - discards pending patch and clears staging
- GET /pending:
  - returns current pending diff and summary
- GET /restore_points:
  - list last 3 commits
- POST /revert { sha }:
  - hard reset repo to sha; rebuild/update index; clear pending + reset context
- POST /run_command { command, require_yes=true }:
  - must return a “needs_confirmation_token” unless user explicitly confirms
  - never executes unless confirmed
- POST /reset_context:
  - clears RLM vars and ephemeral conversation state for this repo/session

RULES (non-negotiable)
- Never directly edit base code without approval.
- Never run shell commands without explicit user confirmation.
- Always return a clear diff summary and risk notes.
- Always keep prompts minimal; retrieve code context via index/ripgrep, not by pasting whole repo.
- Handle external repo edits: if git status changed while pending patch exists, either rebase the patch or invalidate and regenerate.

MILESTONES (implement sequentially; keep repo runnable after each)
1) Wire real /query planner flow:
   - ask clarifying questions when scope unclear
   - implement state machine in agent/
2) Indexer upgrade:
   - implement Tree-sitter symbol extraction for Python and JS/TS at minimum
   - store symbols in SQLite + file mtimes
   - implement incremental reindex on changed files
   - add ripgrep retrieval helper
3) Propose patch generation:
   - implement retrieve->plan->coder producing unified diffs
   - store pending patch with metadata
4) Pending patch iteration:
   - implement /revise_pending to modify pending diff minimally
   - ensure staging reflects pending state
5) Approval/reject hardening:
   - robust git apply
   - commit message generation
   - ring buffer enforcement (last 3)
   - clear pending patch + reset context after approval
6) Command runner with explicit YES gating:
   - never execute without confirmation
   - return captured stdout/stderr
7) RLM harness integration:
   - all LLM calls go through rlm_wrap/
   - store large context externally (vars/DB)
   - implement /reset_context and auto-reset after approval
8) Optional: VSCode/MCP integration (separate module; do not block MVP)

START NOW
- First output: a concrete folder/file plan for changes (by filename).
- Then implement Milestone 1 and Milestone 2 fully, with commands to run in a VM.
- Keep modifications minimal and consistent with existing scaffold code and naming.
